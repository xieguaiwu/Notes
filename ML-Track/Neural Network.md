---
tags:
  - MachineLearning
  - 定义性
title: Neural Network
created: 2025-11-29T09:12:00
modified:
---
# Neural Network
## 1. Overall
机器学习主要分为以下步骤：
![[深度学习三个步骤.png]]

![[不同类的人工神经网络.png]]
- 反馈网络具有记忆（这源自于图中反馈网络上的自反关系[[Reflexive Relation]]），适合处理长文本
- 图网络无方向

## 2.
### 2.1 前馈神经网络
各神经元属于不同层，整个网络中无反馈，信号从输出层转到输入层
**信息传递是单向的**
缺点：
- 连接存在于层与层之间，每层节点无连接（无循环）
- **输入和输出的维度固定**，无法处理变长的序列数据
- 每次输出智能依赖于当前的输入
### 2.2 卷积神经网络
- 全连接网络
	- 权重矩阵的参数极多
- 卷积神经网络
	- 生物学中的感受野
- 特性：
	- 局部连接（**注意力机制**）
	- 权重共享
	- 空间或时间上的次采样
用卷积层来代替全连接层，**可以减少参数数量，提高效率**

通过在局部上特殊地处理节点，卷积神经网络就可以形成注意力机制
例如：
![[二维卷积的注意力机制.png]]
上方显示的是一个进行简单的图像分类功能的二维卷积
![[二维卷积的步长机制.png]]
选择不同的卷积，就可以从不同方向去提取图像的特征

为了提升准确性：
![[卷积中的滤波器.png]]

### 2.3 循环神经网络
属于一种反馈网络
- 通过使用**带自反馈**的神经元，就能够处理任意长度的序列
- 更加符合生物神经网络结构

其数学模型如下：
![[循环神经网络的数学模型.png]]

## 3. 通用近似定理 (Universal Approximation Theorem)
简而言之，此定理在机器学习上的应用是：对于具有**线性输出层**和至少一个**使用“挤压”性质**的激活函数的隐藏层组成的前馈神经网络，只要隐藏层神经元足够，就可以用任何精度来**近似一个定义在实数空间中的有界闭集函数**

## 4. 机器学习的数学模型
### 4.1
模型：
$$y=f^5(f^4(f^3(f^2(f^1(x)))))\Leftrightarrow\text{深层神经网络}$$
其他嵌套层数更小时就属于浅层神经网络
当$f^1(x)=\sigma (W^1x)$时就是神经网络

### 4.2
学习准则：
$$L(y,y^*)$$

### 4.3
优化——梯度下降
$$\frac{\partial L(y,y^*)}{\partial f^1}=\frac{\partial f^2}{\partial f^1}\times \frac{\partial f^3}{\partial f^2}\times\frac{\partial f^4}{\partial f^3}\times\frac{\partial f^5}{\partial f^4}\times\frac{\partial L(y,y^*)}{\partial f^5}$$
优化梯度下降中，链式法则令网络可以自动计算

![[机器学习数学模型2.png]]
如图所示，每个节点上都可以计算对应的偏导数。**反向传播算法只是自动微分的一种特殊形式**

## 5. 优化问题
梯度消失：
![[优化问题.png]]
为解决此问题：
![[最终的激活函数.png]]